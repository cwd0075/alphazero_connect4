{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNwXAVo1UbJH0y02/hqZDGk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"fF9vrB9U9wl0","executionInfo":{"status":"ok","timestamp":1712813386187,"user_tz":-480,"elapsed":586,"user":{"displayName":"David Mak","userId":"16330670194757710136"}}},"outputs":[],"source":["import numpy as np\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","torch.manual_seed(0)\n","\n","from tqdm.notebook import trange\n","##from tqdm import tqdm\n","import random\n","\n","class ConnectFour:\n","    def __init__(self):\n","        self.row_count = 6\n","        self.column_count = 7\n","        self.action_size = self.column_count\n","        self.in_a_row = 4\n","\n","    def get_initial_state(self):\n","        return np.zeros((self.row_count, self.column_count))\n","\n","    def get_next_state(self, state, action, player):\n","        ### the top row is index zero,\n","        ### so the place of action is the highest row of the action column\n","        row = np.max(np.where(state[:, action] == 0))\n","        state[row, action] = player\n","        return state\n","\n","    def get_valid_moves(self, state):\n","        ### return all column index where row 0 is empty\n","        return (state[0] == 0).astype(np.uint8)\n","\n","    def check_win(self, state, action):\n","        if action == None:\n","            return False\n","\n","        row = np.min(np.where(state[:, action] != 0))\n","        column = action\n","        player = state[row][column]\n","\n","        def count(offset_row, offset_column):\n","            for i in range(1, self.in_a_row):\n","                r = row + offset_row * i\n","                c = action + offset_column * i\n","                if (\n","                    r < 0\n","                    or r >= self.row_count\n","                    or c < 0\n","                    or c >= self.column_count\n","                    or state[r][c] != player\n","                ):\n","                    return i - 1\n","            return self.in_a_row - 1\n","\n","        return (\n","            count(1, 0) >= self.in_a_row - 1 # vertical\n","            or (count(0, 1) + count(0, -1)) >= self.in_a_row - 1 # horizontal\n","            or (count(1, 1) + count(-1, -1)) >= self.in_a_row - 1 # top left diagonal\n","            or (count(1, -1) + count(-1, 1)) >= self.in_a_row - 1 # top right diagonal\n","        )\n","\n","    def get_value_and_terminated(self, state, action):\n","        if self.check_win(state, action):\n","            return 1, True\n","        if np.sum(self.get_valid_moves(state)) == 0:\n","            return 0, True\n","        return 0, False\n","\n","    def get_opponent(self, player):\n","        return -player\n","\n","    def get_opponent_value(self, value):\n","        return -value\n","\n","    def change_perspective(self, state, player):\n","        return state * player\n","\n","    def get_encoded_state(self, state):\n","        encoded_state = np.stack(\n","            (state == -1, state == 0, state == 1)\n","        ).astype(np.float32)\n","\n","        return encoded_state\n","\n","class ResNet(nn.Module):\n","    def __init__(self, game, num_resBlocks, num_hidden, device):\n","        super().__init__()\n","        self.device = device\n","        self.startBlock = nn.Sequential(\n","            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(num_hidden),\n","            nn.ReLU()\n","        )\n","\n","        self.backBone = nn.ModuleList(\n","            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n","        )\n","\n","        self.policyHead = nn.Sequential(\n","            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","            nn.Linear(32 * game.row_count * game.column_count, game.action_size)\n","        )\n","\n","        self.valueHead = nn.Sequential(\n","            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(3),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","            nn.Linear(3 * game.row_count * game.column_count, 1),\n","            nn.Tanh()\n","        )\n","        self.to(device)\n","\n","    def forward(self, x):\n","        x = self.startBlock(x)\n","        for resBlock in self.backBone:\n","            x = resBlock(x)\n","        policy = self.policyHead(x)\n","        value = self.valueHead(x)\n","        return policy, value\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, num_hidden):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(num_hidden)\n","        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(num_hidden)\n","\n","    def forward(self, x):\n","        residual = x\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = self.bn2(self.conv2(x))\n","        x += residual\n","        x = F.relu(x)\n","        return x\n","\n","class Node:\n","    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0, visit_count=0):\n","        self.game = game\n","        self.args = args\n","        self.state = state\n","        self.parent = parent\n","        self.action_taken = action_taken\n","\n","        self.children = []\n","        self.prior = prior\n","\n","        self.visit_count = visit_count\n","        self.value_sum = 0\n","\n","    def is_fully_expanded(self):\n","        return len(self.children) > 0\n","\n","    def select(self):\n","        best_child = None\n","        best_ucb = -np.inf\n","\n","        for child in self.children:\n","            ucb = self.get_ucb(child)\n","            if ucb > best_ucb:\n","                best_child = child\n","                best_ucb = ucb\n","\n","        return best_child\n","\n","    def get_ucb(self, child):\n","        if child.visit_count == 0:\n","            q_value = 0\n","        else:\n","            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n","        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n","\n","    def expand(self, policy):\n","        for action, prob in enumerate(policy):\n","            if prob > 0:\n","                child_state = self.state.copy()\n","                child_state = self.game.get_next_state(child_state, action, 1)\n","                child_state = self.game.change_perspective(child_state, player=-1)\n","\n","                child = Node(self.game, self.args, child_state, self, action, prob)\n","                self.children.append(child)\n","\n","        return child\n","\n","\n","    def backpropagate(self, value):\n","        self.value_sum += value\n","        self.visit_count += 1\n","\n","        value = self.game.get_opponent_value(value)\n","        if self.parent is not None:\n","            self.parent.backpropagate(value)\n","\n","class MCTS:\n","    def __init__(self, game, args, model):\n","        self.game = game\n","        self.args = args\n","        self.model = model\n","\n","    @torch.no_grad()\n","    def search(self, state):\n","        root = Node(self.game, self.args, state, visit_count=1)\n","\n","        policy, _ = self.model(\n","            torch.tensor(self.game.get_encoded_state(state), device=self.model.device).unsqueeze(0)\n","        )\n","        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n","        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n","            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n","\n","        valid_moves = self.game.get_valid_moves(state)\n","        policy *= valid_moves\n","        policy /= np.sum(policy)\n","        root.expand(policy)\n","\n","        for search in range(self.args['num_searches']):\n","            node = root\n","\n","            while node.is_fully_expanded():\n","                node = node.select()\n","\n","            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n","            value = self.game.get_opponent_value(value)\n","\n","            if not is_terminal:\n","                policy, value = self.model(\n","                    torch.tensor(self.game.get_encoded_state(node.state), device=self.model.device).unsqueeze(0)\n","                )\n","                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n","                valid_moves = self.game.get_valid_moves(node.state)\n","                policy *= valid_moves\n","                policy /= np.sum(policy)\n","\n","                value = value.item()\n","\n","                node.expand(policy)\n","\n","            node.backpropagate(value)\n","\n","\n","        action_probs = np.zeros(self.game.action_size)\n","        for child in root.children:\n","            action_probs[child.action_taken] = child.visit_count\n","        action_probs /= np.sum(action_probs)\n","        return action_probs\n","\n","class AlphaZero:\n","    def __init__(self, model, optimizer, game, args):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.game = game\n","        self.args = args\n","        self.mcts = MCTS(game, args, model)\n","\n","    def selfPlay(self):\n","        memory = []\n","        player = 1\n","        state = self.game.get_initial_state()\n","\n","        while True:\n","            neutral_state = self.game.change_perspective(state, player)\n","            action_probs = self.mcts.search(neutral_state)\n","\n","            memory.append((neutral_state, action_probs, player))\n","\n","\n","            temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n","            temperature_action_probs /= np.sum(temperature_action_probs)\n","            action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n","\n","            state = self.game.get_next_state(state, action, player)\n","\n","            value, is_terminal = self.game.get_value_and_terminated(state, action)\n","\n","            if is_terminal:\n","                returnMemory = []\n","                for hist_neutral_state, hist_action_probs, hist_player in memory:\n","                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n","                    returnMemory.append((\n","                        self.game.get_encoded_state(hist_neutral_state),\n","                        hist_action_probs,\n","                        hist_outcome\n","                    ))\n","                return returnMemory\n","\n","            player = self.game.get_opponent(player)\n","\n","\n","\n","    def train(self, memory):\n","        random.shuffle(memory)\n","        for batchIdx in range(0, len(memory), self.args['batch_size']):\n","            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n","            state, policy_targets, value_targets = zip(*sample)\n","\n","            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n","\n","            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n","            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n","            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n","\n","            out_policy, out_value = self.model(state)\n","\n","            policy_loss = F.cross_entropy(out_policy, policy_targets)\n","            value_loss = F.mse_loss(out_value, value_targets)\n","            loss = policy_loss + value_loss\n","\n","            self.optimizer.zero_grad() # change to self.optimizer\n","            loss.backward()\n","            self.optimizer.step() # change to self.optimizer\n","\n","    def learn(self):\n","        for iteration in range(self.args['num_iterations']):\n","            memory = []\n","\n","            self.model.eval()\n","            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n","                memory += self.selfPlay()\n","\n","            self.model.train()\n","            for epoch in trange(self.args['num_epochs']):\n","                self.train(memory)\n","\n","            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n","            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")\n","\n","\n","def main():\n","    game = ConnectFour()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    player = 1\n","\n","    args = {\n","        'C': 2,\n","        'num_searches': 100,\n","        'dirichlet_epsilon': 0.,\n","        'dirichlet_alpha': 0.3\n","    }\n","\n","\n","    model = ResNet(game, 9, 128, device=device)\n","    ### model.load_state_dict(torch.load('model_2.pt', map_location=device))\n","    model.eval()\n","    mcts = MCTS(game, args, model)\n","\n","    state = game.get_initial_state()\n","\n","\n","    while True:\n","        print(state)\n","\n","        if player == 1:\n","            valid_moves = game.get_valid_moves(state)\n","            print(\"valid_moves\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n","            action = int(input(f\"{player}:\"))\n","\n","            if valid_moves[action] == 0:\n","                print(\"action not valid\")\n","                continue\n","\n","        else:\n","            neutral_state = game.change_perspective(state, player)\n","            mcts_probs = mcts.search(neutral_state)\n","            action = np.argmax(mcts_probs)\n","\n","        state = game.get_next_state(state, action, player)\n","\n","        value, is_terminal = game.get_value_and_terminated(state, action)\n","\n","        if is_terminal:\n","            print(state)\n","            if value == 1:\n","                print(player, \"won\")\n","            else:\n","                print(\"draw\")\n","            break\n","\n","        player = game.get_opponent(player)\n","\n","def test():\n","    game = ConnectFour()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    state = game.get_initial_state()\n","    state = game.get_next_state(state, 3, -1)\n","    state = game.get_next_state(state, 3, -1)\n","    state = game.get_next_state(state, 3, -1)\n","    state = game.get_next_state(state, 4, 1)\n","    state = game.get_next_state(state, 2, 1)\n","    state = game.get_next_state(state, 5, 1)\n","\n","    print(state)\n","\n","    encoded_state = game.get_encoded_state(state)\n","\n","    print(encoded_state)\n","\n","    tensor_state = torch.tensor(encoded_state, device=device).unsqueeze(0)\n","\n","    model = ResNet(game, 9, 128, device=device)\n","    model.load_state_dict(torch.load('model_7_ConnectFour.pt', map_location=device))\n","\n","    model.eval()\n","\n","\n","    policy, value = model(tensor_state)\n","    value = value.item()\n","    policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n","\n","    print(value, policy)\n"]},{"cell_type":"code","source":["!pip install onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykaCfzGOiQvT","executionInfo":{"status":"ok","timestamp":1712811867014,"user_tz":-480,"elapsed":21432,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"e63b2bf2-91de-4d61-f692-ba0f51a42885"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.16.0\n"]}]},{"cell_type":"code","source":["game = ConnectFour()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","state = game.get_initial_state()\n","state = game.get_next_state(state, 3, -1)\n","state = game.get_next_state(state, 3, -1)\n","state = game.get_next_state(state, 3, -1)\n","state = game.get_next_state(state, 4, 1)\n","state = game.get_next_state(state, 2, 1)\n","state = game.get_next_state(state, 5, 1)\n","\n","print(state)\n","\n","encoded_state = game.get_encoded_state(state)\n","\n","print(encoded_state)\n","\n","tensor_state = torch.tensor(encoded_state, device=device).unsqueeze(0)\n","\n","model = ResNet(game, 9, 128, device=device)\n","model.load_state_dict(torch.load('model_7_ConnectFour.pt', map_location=device))\n","\n","model.eval()\n","\n","model_name = 'onnx_model.onnx'\n","torch.onnx.export(model   = model,\n","                  args    = tensor_state,\n","                  f       = model_name,\n","                  verbose = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qUERA0risli","executionInfo":{"status":"ok","timestamp":1712812677814,"user_tz":-480,"elapsed":3017,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"be2e1ffa-a0b2-4870-b968-08f412b87907"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0. -1.  0.  0.  0.]\n"," [ 0.  0.  0. -1.  0.  0.  0.]\n"," [ 0.  0.  1. -1.  1.  1.  0.]]\n","[[[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0.]]\n","\n"," [[1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 0. 1. 1. 1.]\n","  [1. 1. 1. 0. 1. 1. 1.]\n","  [1. 1. 0. 0. 0. 0. 1.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 1. 1. 0.]]]\n"]}]},{"cell_type":"code","source":["# Test the onnx model health\n","import onnx\n","from onnx.helper import printable_graph\n","# load\n","loaded_model = onnx.load(model_name)\n","# check (well formed)\n","onnx.checker.check_model(loaded_model)\n","print(printable_graph(loaded_model.graph))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JqTDqfp0rPy9","executionInfo":{"status":"ok","timestamp":1712814203559,"user_tz":-480,"elapsed":381,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"6b8d6eb9-a5d1-4d07-9992-5c95e4dd3b73"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["graph main_graph (\n","  %input.1[FLOAT, 1x3x6x7]\n",") initializers (\n","  %policyHead.4.weight[FLOAT, 7x1344]\n","  %policyHead.4.bias[FLOAT, 7]\n","  %valueHead.4.weight[FLOAT, 1x126]\n","  %valueHead.4.bias[FLOAT, 1]\n","  %onnx::Conv_230[FLOAT, 128x3x3x3]\n","  %onnx::Conv_231[FLOAT, 128]\n","  %onnx::Conv_233[FLOAT, 128x128x3x3]\n","  %onnx::Conv_234[FLOAT, 128]\n","  %onnx::Conv_236[FLOAT, 128x128x3x3]\n","  %onnx::Conv_237[FLOAT, 128]\n","  %onnx::Conv_239[FLOAT, 128x128x3x3]\n","  %onnx::Conv_240[FLOAT, 128]\n","  %onnx::Conv_242[FLOAT, 128x128x3x3]\n","  %onnx::Conv_243[FLOAT, 128]\n","  %onnx::Conv_245[FLOAT, 128x128x3x3]\n","  %onnx::Conv_246[FLOAT, 128]\n","  %onnx::Conv_248[FLOAT, 128x128x3x3]\n","  %onnx::Conv_249[FLOAT, 128]\n","  %onnx::Conv_251[FLOAT, 128x128x3x3]\n","  %onnx::Conv_252[FLOAT, 128]\n","  %onnx::Conv_254[FLOAT, 128x128x3x3]\n","  %onnx::Conv_255[FLOAT, 128]\n","  %onnx::Conv_257[FLOAT, 128x128x3x3]\n","  %onnx::Conv_258[FLOAT, 128]\n","  %onnx::Conv_260[FLOAT, 128x128x3x3]\n","  %onnx::Conv_261[FLOAT, 128]\n","  %onnx::Conv_263[FLOAT, 128x128x3x3]\n","  %onnx::Conv_264[FLOAT, 128]\n","  %onnx::Conv_266[FLOAT, 128x128x3x3]\n","  %onnx::Conv_267[FLOAT, 128]\n","  %onnx::Conv_269[FLOAT, 128x128x3x3]\n","  %onnx::Conv_270[FLOAT, 128]\n","  %onnx::Conv_272[FLOAT, 128x128x3x3]\n","  %onnx::Conv_273[FLOAT, 128]\n","  %onnx::Conv_275[FLOAT, 128x128x3x3]\n","  %onnx::Conv_276[FLOAT, 128]\n","  %onnx::Conv_278[FLOAT, 128x128x3x3]\n","  %onnx::Conv_279[FLOAT, 128]\n","  %onnx::Conv_281[FLOAT, 128x128x3x3]\n","  %onnx::Conv_282[FLOAT, 128]\n","  %onnx::Conv_284[FLOAT, 128x128x3x3]\n","  %onnx::Conv_285[FLOAT, 128]\n","  %onnx::Conv_287[FLOAT, 32x128x3x3]\n","  %onnx::Conv_288[FLOAT, 32]\n","  %onnx::Conv_290[FLOAT, 3x128x3x3]\n","  %onnx::Conv_291[FLOAT, 3]\n",") {\n","  %/startBlock/startBlock.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input.1, %onnx::Conv_230, %onnx::Conv_231)\n","  %/startBlock/startBlock.2/Relu_output_0 = Relu(%/startBlock/startBlock.0/Conv_output_0)\n","  %/backBone.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/startBlock/startBlock.2/Relu_output_0, %onnx::Conv_233, %onnx::Conv_234)\n","  %/backBone.0/Relu_output_0 = Relu(%/backBone.0/conv1/Conv_output_0)\n","  %/backBone.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.0/Relu_output_0, %onnx::Conv_236, %onnx::Conv_237)\n","  %/backBone.0/Add_output_0 = Add(%/backBone.0/conv2/Conv_output_0, %/startBlock/startBlock.2/Relu_output_0)\n","  %/backBone.0/Relu_1_output_0 = Relu(%/backBone.0/Add_output_0)\n","  %/backBone.1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.0/Relu_1_output_0, %onnx::Conv_239, %onnx::Conv_240)\n","  %/backBone.1/Relu_output_0 = Relu(%/backBone.1/conv1/Conv_output_0)\n","  %/backBone.1/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.1/Relu_output_0, %onnx::Conv_242, %onnx::Conv_243)\n","  %/backBone.1/Add_output_0 = Add(%/backBone.1/conv2/Conv_output_0, %/backBone.0/Relu_1_output_0)\n","  %/backBone.1/Relu_1_output_0 = Relu(%/backBone.1/Add_output_0)\n","  %/backBone.2/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.1/Relu_1_output_0, %onnx::Conv_245, %onnx::Conv_246)\n","  %/backBone.2/Relu_output_0 = Relu(%/backBone.2/conv1/Conv_output_0)\n","  %/backBone.2/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.2/Relu_output_0, %onnx::Conv_248, %onnx::Conv_249)\n","  %/backBone.2/Add_output_0 = Add(%/backBone.2/conv2/Conv_output_0, %/backBone.1/Relu_1_output_0)\n","  %/backBone.2/Relu_1_output_0 = Relu(%/backBone.2/Add_output_0)\n","  %/backBone.3/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.2/Relu_1_output_0, %onnx::Conv_251, %onnx::Conv_252)\n","  %/backBone.3/Relu_output_0 = Relu(%/backBone.3/conv1/Conv_output_0)\n","  %/backBone.3/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.3/Relu_output_0, %onnx::Conv_254, %onnx::Conv_255)\n","  %/backBone.3/Add_output_0 = Add(%/backBone.3/conv2/Conv_output_0, %/backBone.2/Relu_1_output_0)\n","  %/backBone.3/Relu_1_output_0 = Relu(%/backBone.3/Add_output_0)\n","  %/backBone.4/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.3/Relu_1_output_0, %onnx::Conv_257, %onnx::Conv_258)\n","  %/backBone.4/Relu_output_0 = Relu(%/backBone.4/conv1/Conv_output_0)\n","  %/backBone.4/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.4/Relu_output_0, %onnx::Conv_260, %onnx::Conv_261)\n","  %/backBone.4/Add_output_0 = Add(%/backBone.4/conv2/Conv_output_0, %/backBone.3/Relu_1_output_0)\n","  %/backBone.4/Relu_1_output_0 = Relu(%/backBone.4/Add_output_0)\n","  %/backBone.5/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.4/Relu_1_output_0, %onnx::Conv_263, %onnx::Conv_264)\n","  %/backBone.5/Relu_output_0 = Relu(%/backBone.5/conv1/Conv_output_0)\n","  %/backBone.5/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.5/Relu_output_0, %onnx::Conv_266, %onnx::Conv_267)\n","  %/backBone.5/Add_output_0 = Add(%/backBone.5/conv2/Conv_output_0, %/backBone.4/Relu_1_output_0)\n","  %/backBone.5/Relu_1_output_0 = Relu(%/backBone.5/Add_output_0)\n","  %/backBone.6/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.5/Relu_1_output_0, %onnx::Conv_269, %onnx::Conv_270)\n","  %/backBone.6/Relu_output_0 = Relu(%/backBone.6/conv1/Conv_output_0)\n","  %/backBone.6/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.6/Relu_output_0, %onnx::Conv_272, %onnx::Conv_273)\n","  %/backBone.6/Add_output_0 = Add(%/backBone.6/conv2/Conv_output_0, %/backBone.5/Relu_1_output_0)\n","  %/backBone.6/Relu_1_output_0 = Relu(%/backBone.6/Add_output_0)\n","  %/backBone.7/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.6/Relu_1_output_0, %onnx::Conv_275, %onnx::Conv_276)\n","  %/backBone.7/Relu_output_0 = Relu(%/backBone.7/conv1/Conv_output_0)\n","  %/backBone.7/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.7/Relu_output_0, %onnx::Conv_278, %onnx::Conv_279)\n","  %/backBone.7/Add_output_0 = Add(%/backBone.7/conv2/Conv_output_0, %/backBone.6/Relu_1_output_0)\n","  %/backBone.7/Relu_1_output_0 = Relu(%/backBone.7/Add_output_0)\n","  %/backBone.8/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.7/Relu_1_output_0, %onnx::Conv_281, %onnx::Conv_282)\n","  %/backBone.8/Relu_output_0 = Relu(%/backBone.8/conv1/Conv_output_0)\n","  %/backBone.8/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.8/Relu_output_0, %onnx::Conv_284, %onnx::Conv_285)\n","  %/backBone.8/Add_output_0 = Add(%/backBone.8/conv2/Conv_output_0, %/backBone.7/Relu_1_output_0)\n","  %/backBone.8/Relu_1_output_0 = Relu(%/backBone.8/Add_output_0)\n","  %/policyHead/policyHead.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.8/Relu_1_output_0, %onnx::Conv_287, %onnx::Conv_288)\n","  %/policyHead/policyHead.2/Relu_output_0 = Relu(%/policyHead/policyHead.0/Conv_output_0)\n","  %/policyHead/policyHead.3/Flatten_output_0 = Flatten[axis = 1](%/policyHead/policyHead.2/Relu_output_0)\n","  %222 = Gemm[alpha = 1, beta = 1, transB = 1](%/policyHead/policyHead.3/Flatten_output_0, %policyHead.4.weight, %policyHead.4.bias)\n","  %/valueHead/valueHead.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/backBone.8/Relu_1_output_0, %onnx::Conv_290, %onnx::Conv_291)\n","  %/valueHead/valueHead.2/Relu_output_0 = Relu(%/valueHead/valueHead.0/Conv_output_0)\n","  %/valueHead/valueHead.3/Flatten_output_0 = Flatten[axis = 1](%/valueHead/valueHead.2/Relu_output_0)\n","  %/valueHead/valueHead.4/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%/valueHead/valueHead.3/Flatten_output_0, %valueHead.4.weight, %valueHead.4.bias)\n","  %228 = Tanh(%/valueHead/valueHead.4/Gemm_output_0)\n","  return %222, %228\n","}\n"]}]},{"cell_type":"code","source":["!pip install onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x80AOWxUr0rm","executionInfo":{"status":"ok","timestamp":1712814258836,"user_tz":-480,"elapsed":9598,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"5a58840a-0458-4147-f5ba-2b185e6c7bf3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnxruntime\n","  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1\n"]}]},{"cell_type":"code","source":["# Test run on onnx runtime\n","import onnxruntime as ort\n","ort_session = ort.InferenceSession(model_name)\n","input_name = ort_session.get_inputs()[0].name\n","print(input_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xEeioksUr6dF","executionInfo":{"status":"ok","timestamp":1712814273191,"user_tz":-480,"elapsed":400,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"9f4f1827-d35c-4dfb-ad66-cc04bbf864e7"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["input.1\n"]}]},{"cell_type":"code","source":["game = ConnectFour()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","state = game.get_initial_state()\n","state = game.get_next_state(state, 3, -1)\n","state = game.get_next_state(state, 3, -1)\n","state = game.get_next_state(state, 3, -1)\n","state = game.get_next_state(state, 4, 1)\n","state = game.get_next_state(state, 2, 1)\n","state = game.get_next_state(state, 5, 1)\n","\n","print(state)\n","\n","encoded_state = game.get_encoded_state(state)\n","\n","print(encoded_state)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7u0mh4rEtAIX","executionInfo":{"status":"ok","timestamp":1712814603270,"user_tz":-480,"elapsed":411,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"4825e192-a464-4d92-9004-e29fd287a863"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0. -1.  0.  0.  0.]\n"," [ 0.  0.  0. -1.  0.  0.  0.]\n"," [ 0.  0.  1. -1.  1.  1.  0.]]\n","[[[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0.]]\n","\n"," [[1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 0. 1. 1. 1.]\n","  [1. 1. 1. 0. 1. 1. 1.]\n","  [1. 1. 0. 0. 0. 0. 1.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 1. 1. 0.]]]\n"]}]},{"cell_type":"code","source":["print(encoded_state.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Y-LPhXrtMYV","executionInfo":{"status":"ok","timestamp":1712814685393,"user_tz":-480,"elapsed":385,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"1f5895b6-c30d-4205-a1a1-f59e2d7c4edf"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(3, 6, 7)\n"]}]},{"cell_type":"code","source":["input_reshaped = encoded_state.reshape(1, 3, 6, 7)"],"metadata":{"id":"RsJRlfEctkVN","executionInfo":{"status":"ok","timestamp":1712814713797,"user_tz":-480,"elapsed":390,"user":{"displayName":"David Mak","userId":"16330670194757710136"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","import numpy as np\n","X = np.array(input_reshaped)\n","outputs = ort_session.run(\n","    None,\n","    {input_name: X.astype(np.float32)},\n",")\n","print(outputs[1].squeeze())\n","#policy_np = np.softmax(outputs[0], axis=1).squeeze().detach().cpu().numpy()\n","policy_np = np.exp(outputs[0]) / np.sum(np.exp(outputs[0]), axis=1)\n","print(policy_np.squeeze())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXP_1Z8Qtq1l","executionInfo":{"status":"ok","timestamp":1712814761936,"user_tz":-480,"elapsed":383,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"0bba2d22-b22f-4c3b-9fc5-19c9ef6cbcc6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["-0.64555633\n","[0.0023571  0.00160517 0.01919002 0.95855933 0.00587676 0.00798753\n"," 0.00442401]\n"]}]},{"cell_type":"code","source":["    ### test the trained Connect4 model\n","    ### compare to original pytorch version\n","    test()"],"metadata":{"id":"KDxMFtBi-MGC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712814863382,"user_tz":-480,"elapsed":376,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"80500d8d-52ec-447d-9a72-f7dee8bad7db"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0.  0.  0.  0.  0.]\n"," [ 0.  0.  0. -1.  0.  0.  0.]\n"," [ 0.  0.  0. -1.  0.  0.  0.]\n"," [ 0.  0.  1. -1.  1.  1.  0.]]\n","[[[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0.]]\n","\n"," [[1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 1. 1. 1. 1.]\n","  [1. 1. 1. 0. 1. 1. 1.]\n","  [1. 1. 1. 0. 1. 1. 1.]\n","  [1. 1. 0. 0. 0. 0. 1.]]\n","\n"," [[0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 1. 1. 0.]]]\n","-0.6455562114715576 [0.0023571  0.00160517 0.01919001 0.9585594  0.00587676 0.00798753\n"," 0.00442401]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"EgzSaetK-XSy"},"execution_count":null,"outputs":[]}]}