{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31733,
     "status": "ok",
     "timestamp": 1712726755787,
     "user": {
      "displayName": "David Mak",
      "userId": "16330670194757710136"
     },
     "user_tz": -480
    },
    "id": "KEm6JElBqxPJ",
    "outputId": "ba9560f0-b3d6-4e41-9cc4-0e2f4ce0ab40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ray\n",
      "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray) (4.19.2)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray)\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray) (23.1)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray)\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray) (6.0.1)\n",
      "Collecting aiosignal (from ray)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist (from ray)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray) (2.31.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray) (0.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray) (2024.2.2)\n",
      "Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.1/385.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, msgpack, frozenlist, aiosignal, ray\n",
      "Successfully installed aiosignal-1.3.1 frozenlist-1.4.1 msgpack-1.0.8 protobuf-5.26.1 ray-2.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 07:13:40,236\tWARNING utils.py:580 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.\n",
      "2024-04-10 07:13:40,238\tWARNING utils.py:592 -- Ray currently does not support initializing Ray with fractional cpus. Your num_cpus will be truncated from 15.36 to 15.\n",
      "2024-04-10 07:13:40,328\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 7516184576 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-04-10 07:13:41,488\tINFO worker.py:1752 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node:__internal_head__': 1.0,\n",
       " 'accelerator_type:TITAN': 1.0,\n",
       " 'CPU': 15.0,\n",
       " 'object_store_memory': 10000000000.0,\n",
       " 'memory': 29781571789.0,\n",
       " 'GPU': 1.0,\n",
       " 'node:172.17.0.6': 1.0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install ray\n",
    "import ray\n",
    "ray.init()\n",
    "ray.available_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4170,
     "status": "ok",
     "timestamp": 1712726778579,
     "user": {
      "displayName": "David Mak",
      "userId": "16330670194757710136"
     },
     "user_tz": -480
    },
    "id": "fF9vrB9U9wl0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "##from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "class ConnectFour:\n",
    "    def __init__(self):\n",
    "        self.row_count = 6\n",
    "        self.column_count = 7\n",
    "        self.action_size = self.column_count\n",
    "        self.in_a_row = 4\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        return np.zeros((self.row_count, self.column_count))\n",
    "\n",
    "    def get_next_state(self, state, action, player):\n",
    "        ### the top row is index zero,\n",
    "        ### so the place of action is the highest row of the action column\n",
    "        row = np.max(np.where(state[:, action] == 0))\n",
    "        state[row, action] = player\n",
    "        return state\n",
    "\n",
    "    def get_valid_moves(self, state):\n",
    "        ### return all column index where row 0 is empty\n",
    "        return (state[0] == 0).astype(np.uint8)\n",
    "\n",
    "    def check_win(self, state, action):\n",
    "        if action == None:\n",
    "            return False\n",
    "\n",
    "        row = np.min(np.where(state[:, action] != 0))\n",
    "        column = action\n",
    "        player = state[row][column]\n",
    "\n",
    "        def count(offset_row, offset_column):\n",
    "            for i in range(1, self.in_a_row):\n",
    "                r = row + offset_row * i\n",
    "                c = action + offset_column * i\n",
    "                if (\n",
    "                    r < 0\n",
    "                    or r >= self.row_count\n",
    "                    or c < 0\n",
    "                    or c >= self.column_count\n",
    "                    or state[r][c] != player\n",
    "                ):\n",
    "                    return i - 1\n",
    "            return self.in_a_row - 1\n",
    "\n",
    "        return (\n",
    "            count(1, 0) >= self.in_a_row - 1 # vertical\n",
    "            or (count(0, 1) + count(0, -1)) >= self.in_a_row - 1 # horizontal\n",
    "            or (count(1, 1) + count(-1, -1)) >= self.in_a_row - 1 # top left diagonal\n",
    "            or (count(1, -1) + count(-1, 1)) >= self.in_a_row - 1 # top right diagonal\n",
    "        )\n",
    "\n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        if self.check_win(state, action):\n",
    "            return 1, True\n",
    "        if np.sum(self.get_valid_moves(state)) == 0:\n",
    "            return 0, True\n",
    "        return 0, False\n",
    "\n",
    "    def get_opponent(self, player):\n",
    "        return -player\n",
    "\n",
    "    def get_opponent_value(self, value):\n",
    "        return -value\n",
    "\n",
    "    def change_perspective(self, state, player):\n",
    "        return state * player\n",
    "\n",
    "    def get_encoded_state(self, state):\n",
    "        encoded_state = np.stack(\n",
    "            (state == -1, state == 0, state == 1)\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        return encoded_state\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, game, num_resBlocks, num_hidden, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
    "        )\n",
    "\n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * game.row_count * game.column_count, game.action_size)\n",
    "        )\n",
    "\n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * game.row_count * game.column_count, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
    "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0, visit_count=0):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "\n",
    "        self.children = []\n",
    "        self.prior = prior\n",
    "\n",
    "        self.visit_count = visit_count\n",
    "        self.value_sum = 0\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "\n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_child = child\n",
    "                best_ucb = ucb\n",
    "\n",
    "        return best_child\n",
    "\n",
    "    def get_ucb(self, child):\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
    "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n",
    "\n",
    "    def expand(self, policy):\n",
    "        for action, prob in enumerate(policy):\n",
    "            if prob > 0:\n",
    "                child_state = self.state.copy()\n",
    "                child_state = self.game.get_next_state(child_state, action, 1)\n",
    "                child_state = self.game.change_perspective(child_state, player=-1)\n",
    "\n",
    "                child = Node(self.game, self.args, child_state, self, action, prob)\n",
    "                self.children.append(child)\n",
    "\n",
    "        return child\n",
    "\n",
    "\n",
    "    def backpropagate(self, value):\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "\n",
    "        value = self.game.get_opponent_value(value)\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, args, model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, state):\n",
    "        root = Node(self.game, self.args, state, visit_count=1)\n",
    "\n",
    "        policy, _ = self.model(\n",
    "            torch.tensor(self.game.get_encoded_state(state), device=self.model.device).unsqueeze(0)\n",
    "        )\n",
    "        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
    "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n",
    "\n",
    "        valid_moves = self.game.get_valid_moves(state)\n",
    "        policy *= valid_moves\n",
    "        policy /= np.sum(policy)\n",
    "        root.expand(policy)\n",
    "\n",
    "        for search in range(self.args['num_searches']):\n",
    "            node = root\n",
    "\n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "\n",
    "            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "            value = self.game.get_opponent_value(value)\n",
    "\n",
    "            if not is_terminal:\n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(self.game.get_encoded_state(node.state), device=self.model.device).unsqueeze(0)\n",
    "                )\n",
    "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "                valid_moves = self.game.get_valid_moves(node.state)\n",
    "                policy *= valid_moves\n",
    "                policy /= np.sum(policy)\n",
    "\n",
    "                value = value.item()\n",
    "\n",
    "                node.expand(policy)\n",
    "\n",
    "            node.backpropagate(value)\n",
    "\n",
    "\n",
    "        action_probs = np.zeros(self.game.action_size)\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        return action_probs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AlphaZero:\n",
    "    def __init__(self, model, optimizer, game, args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.mcts = MCTS(game, args, model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def selfPlay(self):\n",
    "      memory = []\n",
    "      player = 1\n",
    "      state = self.game.get_initial_state()\n",
    "\n",
    "      while True:\n",
    "          neutral_state = self.game.change_perspective(state, player)\n",
    "          action_probs = self.mcts.search(neutral_state)\n",
    "\n",
    "          memory.append((neutral_state, action_probs, player))\n",
    "\n",
    "\n",
    "          temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
    "          temperature_action_probs /= np.sum(temperature_action_probs)\n",
    "          action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
    "\n",
    "          state = self.game.get_next_state(state, action, player)\n",
    "\n",
    "          value, is_terminal = self.game.get_value_and_terminated(state, action)\n",
    "\n",
    "          if is_terminal:\n",
    "              returnMemory = []\n",
    "              for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
    "                  hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
    "                  returnMemory.append((\n",
    "                      self.game.get_encoded_state(hist_neutral_state),\n",
    "                      hist_action_probs,\n",
    "                      hist_outcome\n",
    "                  ))\n",
    "              return returnMemory\n",
    "\n",
    "          player = self.game.get_opponent(player)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "\n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "\n",
    "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
    "\n",
    "            out_policy, out_value = self.model(state)\n",
    "\n",
    "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "            value_loss = F.mse_loss(out_value, value_targets)\n",
    "            loss = policy_loss + value_loss\n",
    "\n",
    "            self.optimizer.zero_grad() # change to self.optimizer\n",
    "            loss.backward()\n",
    "            self.optimizer.step() # change to self.optimizer\n",
    "\n",
    "    def learn(self):\n",
    "        for iteration in range(self.args['num_iterations']):\n",
    "            memory = []\n",
    "\n",
    "            self.model.eval()\n",
    "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n",
    "\n",
    "                memory += self.selfPlay()\n",
    "\n",
    "            self.model.train()\n",
    "            for epoch in trange(self.args['num_epochs']):\n",
    "                self.train(memory)\n",
    "\n",
    "            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    game = ConnectFour()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    player = 1\n",
    "\n",
    "    args = {\n",
    "        'C': 2,\n",
    "        'num_searches': 100,\n",
    "        'dirichlet_epsilon': 0.,\n",
    "        'dirichlet_alpha': 0.3\n",
    "    }\n",
    "\n",
    "\n",
    "    model = ResNet(game, 9, 128, device=device)\n",
    "    ### model.load_state_dict(torch.load('model_2.pt', map_location=device))\n",
    "    model.eval()\n",
    "    mcts = MCTS(game, args, model)\n",
    "\n",
    "    state = game.get_initial_state()\n",
    "\n",
    "\n",
    "    while True:\n",
    "        print(state)\n",
    "\n",
    "        if player == 1:\n",
    "            valid_moves = game.get_valid_moves(state)\n",
    "            print(\"valid_moves\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
    "            action = int(input(f\"{player}:\"))\n",
    "\n",
    "            if valid_moves[action] == 0:\n",
    "                print(\"action not valid\")\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            neutral_state = game.change_perspective(state, player)\n",
    "            mcts_probs = mcts.search(neutral_state)\n",
    "            action = np.argmax(mcts_probs)\n",
    "\n",
    "        state = game.get_next_state(state, action, player)\n",
    "\n",
    "        value, is_terminal = game.get_value_and_terminated(state, action)\n",
    "\n",
    "        if is_terminal:\n",
    "            print(state)\n",
    "            if value == 1:\n",
    "                print(player, \"won\")\n",
    "            else:\n",
    "                print(\"draw\")\n",
    "            break\n",
    "\n",
    "        player = game.get_opponent(player)\n",
    "\n",
    "def test():\n",
    "\n",
    "    tictactoe = TicTacToe()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state = tictactoe.get_initial_state()\n",
    "    state = tictactoe.get_next_state(state, 2, -1)\n",
    "    state = tictactoe.get_next_state(state, 4, -1)\n",
    "    state = tictactoe.get_next_state(state, 6, 1)\n",
    "    state = tictactoe.get_next_state(state, 8, 1)\n",
    "\n",
    "    print(state)\n",
    "\n",
    "    encoded_state = tictactoe.get_encoded_state(state)\n",
    "\n",
    "    print(encoded_state)\n",
    "\n",
    "    tensor_state = torch.tensor(encoded_state, device=device).unsqueeze(0)\n",
    "\n",
    "    model = ResNet(tictactoe, 4, 64, device=device)\n",
    "    model.load_state_dict(torch.load('model_2.pt', map_location=device))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    policy, value = model(tensor_state)\n",
    "    value = value.item()\n",
    "    policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "    print(value, policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1712727996768,
     "user": {
      "displayName": "David Mak",
      "userId": "16330670194757710136"
     },
     "user_tz": -480
    },
    "id": "hVdRBWvyZZ2E"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "@ray.remote(num_gpus=0.2)\n",
    "def selfPlay(model, optimizer, game, args):\n",
    "  memory = []\n",
    "  player = 1\n",
    "  state = game.get_initial_state()\n",
    "  mcts = MCTS(game, args, model)\n",
    "  while True:\n",
    "      neutral_state = game.change_perspective(state, player)\n",
    "      action_probs = mcts.search(neutral_state)\n",
    "\n",
    "      memory.append((neutral_state, action_probs, player))\n",
    "\n",
    "\n",
    "      temperature_action_probs = action_probs ** (1 / args['temperature'])\n",
    "      temperature_action_probs /= np.sum(temperature_action_probs)\n",
    "      action = np.random.choice(game.action_size, p=temperature_action_probs)\n",
    "\n",
    "      state = game.get_next_state(state, action, player)\n",
    "\n",
    "      value, is_terminal = game.get_value_and_terminated(state, action)\n",
    "\n",
    "      if is_terminal:\n",
    "          returnMemory = []\n",
    "          for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
    "              hist_outcome = value if hist_player == player else game.get_opponent_value(value)\n",
    "              returnMemory.append((\n",
    "                  game.get_encoded_state(hist_neutral_state),\n",
    "                  hist_action_probs,\n",
    "                  hist_outcome\n",
    "              ))\n",
    "\n",
    "          return returnMemory\n",
    "\n",
    "      player = game.get_opponent(player)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(memory, model, optimizer, game, args):\n",
    "    random.shuffle(memory)\n",
    "    for batchIdx in range(0, len(memory), args['batch_size']):\n",
    "        sample = memory[batchIdx:min(len(memory) - 1, batchIdx + args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
    "        state, policy_targets, value_targets = zip(*sample)\n",
    "\n",
    "        state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "\n",
    "        state = torch.tensor(state, dtype=torch.float32, device=model.device)\n",
    "        policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=model.device)\n",
    "        value_targets = torch.tensor(value_targets, dtype=torch.float32, device=model.device)\n",
    "\n",
    "        out_policy, out_value = model(state)\n",
    "\n",
    "        policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "        value_loss = F.mse_loss(out_value, value_targets)\n",
    "        loss = policy_loss + value_loss\n",
    "\n",
    "        optimizer.zero_grad() # change to self.optimizer\n",
    "        loss.backward()\n",
    "        optimizer.step() # change to self.optimizer\n",
    "\n",
    "def learn(model, optimizer, game, args):\n",
    "    for iteration in range(args['num_iterations']):\n",
    "        memory = []\n",
    "        results = []\n",
    "        model.eval()\n",
    "        for selfPlay_iteration in trange(args['num_selfPlay_iterations']):\n",
    "            results.append(selfPlay.remote(model, optimizer, game, args))\n",
    "        output = ray.get(results)\n",
    "\n",
    "        for i in range(len(output)):\n",
    "            memory += output[i]\n",
    "        ## print(memory);\n",
    "        ## memory += selfPlay()\n",
    "\n",
    "        model.train()\n",
    "        for epoch in trange(args['num_epochs']):\n",
    "            train(memory, model, optimizer, game, args)\n",
    "\n",
    "        torch.save(model.state_dict(), f\"model_{iteration}.pt\")\n",
    "        torch.save(optimizer.state_dict(), f\"optimizer_{iteration}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "452fc1986fdf42a0847a989aeb492a90",
      "0a71d84a7ee84e3eb34325420dede3b8",
      "2d2c6f3ebe394260858f07fcf9eca3ac",
      "9a94d19891744cfbb10a1403158fbb4a",
      "9585cd92482449249752dd248eeb8817",
      "b88ce4bfe9a341f1a2b06a31f444c4cc",
      "efc78d15dd1d4e27b8124d237ad06a83",
      "93cf138c45bf4d57a00a0fdc7b7739ae",
      "84cf6d6f49614ecf9567c5c092916fcf",
      "4e1df1f810334e688bbd30e7cf0cfde8",
      "5c18f26514c447149ca51f8465f409ac",
      "4e5a8feb5ce24295ad989ba5659359e8",
      "6f4f086559da498ba4cc557d2efcb6d1",
      "1dd67ba2eef344c8a6a526856e2fd31c",
      "6486ac08c27b4a43bb0ef23a02b50f0f",
      "68ae14123aa4462a893021ab9dc1e8c3",
      "83ceef7924804a3ba99d7142bfff1262",
      "b670c07b8b6c4a48ad0e65786a2e0428",
      "e5906ab4846f42648a2372192ee735d6",
      "df49fec580764924aa3aaab2007fdc6d",
      "50df72cb875c4cf3afc79200dc8f7a93",
      "0512b86f2aff43a4ae59ca914f32d860"
     ]
    },
    "executionInfo": {
     "elapsed": 79833,
     "status": "ok",
     "timestamp": 1712728151480,
     "user": {
      "displayName": "David Mak",
      "userId": "16330670194757710136"
     },
     "user_tz": -480
    },
    "id": "lhtEPwmv-B7j",
    "outputId": "959557ad-80aa-4b7d-c5ca-6bbe4e97fad8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfc1acc8a1f40d7800dba22992e1b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce07750897eb4be98ef95aedadb90fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.09848499298096\n"
     ]
    }
   ],
   "source": [
    "    ### Start Training\n",
    "    import time\n",
    "    game = ConnectFour()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = ResNet(game, 9, 128, device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "    args = {\n",
    "        'C': 2,\n",
    "        'num_searches': 600,\n",
    "        'num_iterations': 1,\n",
    "        'num_selfPlay_iterations': 10,\n",
    "        'num_epochs': 1,\n",
    "        'batch_size': 128,\n",
    "        'temperature': 1.25,\n",
    "        'dirichlet_epsilon': 0.25,\n",
    "        'dirichlet_alpha': 0.3\n",
    "    }\n",
    "\n",
    "    ##alphaZero = AlphaZero.remote(model, optimizer, game, args)\n",
    "    ##alphaZero.learn.remote()\n",
    "    start = time.time()\n",
    "    learn(model, optimizer, game, args)\n",
    "    runtime = time.time()-start\n",
    "    print(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1710837309874,
     "user": {
      "displayName": "David Mak",
      "userId": "16330670194757710136"
     },
     "user_tz": -480
    },
    "id": "KDxMFtBi-MGC",
    "outputId": "172efc82-eba5-4868-99d7-ca47b2acb6b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0. -1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 1.  0.  1.]]\n",
      "[[[0. 0. 1.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 0.]\n",
      "  [1. 0. 1.]\n",
      "  [0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 0. 1.]]]\n",
      "-0.08826334774494171 [0.07518821 0.08451733 0.11294591 0.09931102 0.0952905  0.17337684\n",
      " 0.12486862 0.14422536 0.09027616]\n"
     ]
    }
   ],
   "source": [
    "    ### test the trained model, not used in Connect4\n",
    "    ### test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 5123,
     "status": "error",
     "timestamp": 1712651756985,
     "user": {
      "displayName": "David Mak",
      "userId": "16330670194757710136"
     },
     "user_tz": -480
    },
    "id": "pqW64Q3t-PCS",
    "outputId": "c7053a01-734b-4789-c453-1a561b5c213c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "valid_moves [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ae864257e428>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### play the actual game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-4478015015e5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mvalid_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_valid_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"valid_moves\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalid_moves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{player}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalid_moves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "  ### play the actual game\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712647363895,
     "user": {
      "displayName": "David Mak",
      "userId": "16330670194757710136"
     },
     "user_tz": -480
    },
    "id": "EgzSaetK-XSy",
    "outputId": "b7344ab8-7378-4bf3-aa98-4f2d80bbeec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [1, 1], [2, 1], [2, 2]]\n"
     ]
    }
   ],
   "source": [
    "a = [[0, 1], [1, 1]]\n",
    "b = [[2, 1], [2, 2]]\n",
    "d = [a, b]\n",
    "c = a + b\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IWWadivvNi4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNgqXntOelysMOWAl3o/YIM",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0512b86f2aff43a4ae59ca914f32d860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a71d84a7ee84e3eb34325420dede3b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b88ce4bfe9a341f1a2b06a31f444c4cc",
      "placeholder": "​",
      "style": "IPY_MODEL_efc78d15dd1d4e27b8124d237ad06a83",
      "value": "100%"
     }
    },
    "1dd67ba2eef344c8a6a526856e2fd31c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5906ab4846f42648a2372192ee735d6",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df49fec580764924aa3aaab2007fdc6d",
      "value": 4
     }
    },
    "2d2c6f3ebe394260858f07fcf9eca3ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93cf138c45bf4d57a00a0fdc7b7739ae",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84cf6d6f49614ecf9567c5c092916fcf",
      "value": 2
     }
    },
    "452fc1986fdf42a0847a989aeb492a90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a71d84a7ee84e3eb34325420dede3b8",
       "IPY_MODEL_2d2c6f3ebe394260858f07fcf9eca3ac",
       "IPY_MODEL_9a94d19891744cfbb10a1403158fbb4a"
      ],
      "layout": "IPY_MODEL_9585cd92482449249752dd248eeb8817"
     }
    },
    "4e1df1f810334e688bbd30e7cf0cfde8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e5a8feb5ce24295ad989ba5659359e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f4f086559da498ba4cc557d2efcb6d1",
       "IPY_MODEL_1dd67ba2eef344c8a6a526856e2fd31c",
       "IPY_MODEL_6486ac08c27b4a43bb0ef23a02b50f0f"
      ],
      "layout": "IPY_MODEL_68ae14123aa4462a893021ab9dc1e8c3"
     }
    },
    "50df72cb875c4cf3afc79200dc8f7a93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c18f26514c447149ca51f8465f409ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6486ac08c27b4a43bb0ef23a02b50f0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50df72cb875c4cf3afc79200dc8f7a93",
      "placeholder": "​",
      "style": "IPY_MODEL_0512b86f2aff43a4ae59ca914f32d860",
      "value": " 4/4 [00:00&lt;00:00, 29.01it/s]"
     }
    },
    "68ae14123aa4462a893021ab9dc1e8c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f4f086559da498ba4cc557d2efcb6d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83ceef7924804a3ba99d7142bfff1262",
      "placeholder": "​",
      "style": "IPY_MODEL_b670c07b8b6c4a48ad0e65786a2e0428",
      "value": "100%"
     }
    },
    "83ceef7924804a3ba99d7142bfff1262": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84cf6d6f49614ecf9567c5c092916fcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "93cf138c45bf4d57a00a0fdc7b7739ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9585cd92482449249752dd248eeb8817": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a94d19891744cfbb10a1403158fbb4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e1df1f810334e688bbd30e7cf0cfde8",
      "placeholder": "​",
      "style": "IPY_MODEL_5c18f26514c447149ca51f8465f409ac",
      "value": " 2/2 [00:00&lt;00:00,  6.76it/s]"
     }
    },
    "b670c07b8b6c4a48ad0e65786a2e0428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b88ce4bfe9a341f1a2b06a31f444c4cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df49fec580764924aa3aaab2007fdc6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e5906ab4846f42648a2372192ee735d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efc78d15dd1d4e27b8124d237ad06a83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
