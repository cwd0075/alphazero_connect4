{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNgSUAIE72l9hHk0DZPELBo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d86bf1fd196544b6a1c01875d173beb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1186a282fa0447e85ef10c97183be4a","IPY_MODEL_106133254d234474a892386f53ddd2de","IPY_MODEL_6515037cec0344ed9fdea0b5c8b5cfab"],"layout":"IPY_MODEL_927dad273e384632b8f083a19fc965df"}},"e1186a282fa0447e85ef10c97183be4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca2570661a934fb08d3e1aeefc9f393d","placeholder":"​","style":"IPY_MODEL_34cbf38dd87945ef952e3c8cfe9e3a8e","value":"  0%"}},"106133254d234474a892386f53ddd2de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e6882d072884320944d11ce4f06a5a1","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26e9773c57014215ae9cc7f7c698f4c1","value":0}},"6515037cec0344ed9fdea0b5c8b5cfab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6eedbbfa72046e3a79ce94049f83a81","placeholder":"​","style":"IPY_MODEL_2ce0b3e671914a6cb392584909ec046c","value":" 0/500 [00:13&lt;?, ?it/s]"}},"927dad273e384632b8f083a19fc965df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca2570661a934fb08d3e1aeefc9f393d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34cbf38dd87945ef952e3c8cfe9e3a8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e6882d072884320944d11ce4f06a5a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26e9773c57014215ae9cc7f7c698f4c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6eedbbfa72046e3a79ce94049f83a81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ce0b3e671914a6cb392584909ec046c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"444a19ac87fb4f739b7e194350df13a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1cc4e3656e9b439e9676b872bbdd165e","IPY_MODEL_08fd3e8e3d7647348f147864896917ef","IPY_MODEL_ff2e32d9178f49cc80b233fbc2da216c"],"layout":"IPY_MODEL_445b37d1751d4de28c38d795b201c59f"}},"1cc4e3656e9b439e9676b872bbdd165e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a088d99dda34e6184d5ffcbe0186428","placeholder":"​","style":"IPY_MODEL_44dec3690ada4b8fb683c5c8555423e0","value":"100%"}},"08fd3e8e3d7647348f147864896917ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b53cfa79dc84869babc9d8edbb34a0b","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74ddd52026294163ad3b4d042f1a3b78","value":10}},"ff2e32d9178f49cc80b233fbc2da216c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71027508e79442bb858652662838a920","placeholder":"​","style":"IPY_MODEL_87f0386fbab54007af13b614d8dd5e8e","value":" 10/10 [00:01&lt;00:00,  6.39it/s]"}},"445b37d1751d4de28c38d795b201c59f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a088d99dda34e6184d5ffcbe0186428":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44dec3690ada4b8fb683c5c8555423e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b53cfa79dc84869babc9d8edbb34a0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74ddd52026294163ad3b4d042f1a3b78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71027508e79442bb858652662838a920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87f0386fbab54007af13b614d8dd5e8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["! pip install ray\n","import ray\n","ray.init()\n","ray.available_resources()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4SkBH46Jrnm","executionInfo":{"status":"ok","timestamp":1713350299119,"user_tz":-480,"elapsed":19294,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"c073b3b6-4952-469e-e8e4-29f0f5f94423"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ray\n","  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.13.4)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.19.2)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.0)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.1)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.31.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.34.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.2.2)\n","Installing collected packages: ray\n","Successfully installed ray-2.10.0\n"]},{"output_type":"stream","name":"stderr","text":["2024-04-17 10:37:04,159\tINFO worker.py:1752 -- Started a local Ray instance.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'GPU': 1.0,\n"," 'node:172.28.0.12': 1.0,\n"," 'object_store_memory': 4011695308.0,\n"," 'CPU': 2.0,\n"," 'accelerator_type:T4': 1.0,\n"," 'node:__internal_head__': 1.0,\n"," 'memory': 8023390619.0}"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"fF9vrB9U9wl0","executionInfo":{"status":"ok","timestamp":1713350376100,"user_tz":-480,"elapsed":3867,"user":{"displayName":"David Mak","userId":"16330670194757710136"}}},"outputs":[],"source":["import numpy as np\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","torch.manual_seed(0)\n","\n","from tqdm.notebook import trange\n","##from tqdm import tqdm\n","import random\n","import time\n","\n","class ConnectFour:\n","    def __init__(self):\n","        self.row_count = 6\n","        self.column_count = 7\n","        self.action_size = self.column_count\n","        self.in_a_row = 4\n","\n","    def get_initial_state(self):\n","        return np.zeros((self.row_count, self.column_count))\n","\n","    def get_next_state(self, state, action, player):\n","        ### the top row is index zero,\n","        ### so the place of action is the highest row of the action column\n","        row = np.max(np.where(state[:, action] == 0))\n","        state[row, action] = player\n","        return state\n","\n","    def get_valid_moves(self, state):\n","        ### return all column index where row 0 is empty\n","        return (state[0] == 0).astype(np.uint8)\n","\n","    def check_win(self, state, action):\n","        if action == None:\n","            return False\n","\n","        row = np.min(np.where(state[:, action] != 0))\n","        column = action\n","        player = state[row][column]\n","\n","        def count(offset_row, offset_column):\n","            for i in range(1, self.in_a_row):\n","                r = row + offset_row * i\n","                c = action + offset_column * i\n","                if (\n","                    r < 0\n","                    or r >= self.row_count\n","                    or c < 0\n","                    or c >= self.column_count\n","                    or state[r][c] != player\n","                ):\n","                    return i - 1\n","            return self.in_a_row - 1\n","\n","        return (\n","            count(1, 0) >= self.in_a_row - 1 # vertical\n","            or (count(0, 1) + count(0, -1)) >= self.in_a_row - 1 # horizontal\n","            or (count(1, 1) + count(-1, -1)) >= self.in_a_row - 1 # top left diagonal\n","            or (count(1, -1) + count(-1, 1)) >= self.in_a_row - 1 # top right diagonal\n","        )\n","\n","    def get_value_and_terminated(self, state, action):\n","        if self.check_win(state, action):\n","            return 1, True\n","        if np.sum(self.get_valid_moves(state)) == 0:\n","            return 0, True\n","        return 0, False\n","\n","    def get_opponent(self, player):\n","        return -player\n","\n","    def get_opponent_value(self, value):\n","        return -value\n","\n","    def change_perspective(self, state, player):\n","        return state * player\n","\n","    def get_encoded_state(self, state):\n","        encoded_state = np.stack(\n","            (state == -1, state == 0, state == 1)\n","        ).astype(np.float32)\n","\n","        return encoded_state\n","\n","class ResNet(nn.Module):\n","    def __init__(self, game, num_resBlocks, num_hidden, device):\n","        super().__init__()\n","        self.device = device\n","        self.startBlock = nn.Sequential(\n","            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(num_hidden),\n","            nn.ReLU()\n","        )\n","\n","        self.backBone = nn.ModuleList(\n","            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n","        )\n","\n","        self.policyHead = nn.Sequential(\n","            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","            nn.Linear(32 * game.row_count * game.column_count, game.action_size)\n","        )\n","\n","        self.valueHead = nn.Sequential(\n","            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(3),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","            nn.Linear(3 * game.row_count * game.column_count, 1),\n","            nn.Tanh()\n","        )\n","        self.to(device)\n","\n","    def forward(self, x):\n","        x = self.startBlock(x)\n","        for resBlock in self.backBone:\n","            x = resBlock(x)\n","        policy = self.policyHead(x)\n","        value = self.valueHead(x)\n","        return policy, value\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, num_hidden):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(num_hidden)\n","        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(num_hidden)\n","\n","    def forward(self, x):\n","        residual = x\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = self.bn2(self.conv2(x))\n","        x += residual\n","        x = F.relu(x)\n","        return x\n","\n","class Node:\n","    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0, visit_count=0):\n","        self.game = game\n","        self.args = args\n","        self.state = state\n","        self.parent = parent\n","        self.action_taken = action_taken\n","\n","        self.children = []\n","        self.prior = prior\n","\n","        self.visit_count = visit_count\n","        self.value_sum = 0\n","\n","    def is_fully_expanded(self):\n","        return len(self.children) > 0\n","\n","    def select(self):\n","        best_child = None\n","        best_ucb = -np.inf\n","\n","        for child in self.children:\n","            ucb = self.get_ucb(child)\n","            if ucb > best_ucb:\n","                best_child = child\n","                best_ucb = ucb\n","\n","        return best_child\n","\n","    def get_ucb(self, child):\n","        if child.visit_count == 0:\n","            q_value = 0\n","        else:\n","            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n","        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n","\n","    def expand(self, policy):\n","        for action, prob in enumerate(policy):\n","            if prob > 0:\n","                child_state = self.state.copy()\n","                child_state = self.game.get_next_state(child_state, action, 1)\n","                child_state = self.game.change_perspective(child_state, player=-1)\n","\n","                child = Node(self.game, self.args, child_state, self, action, prob)\n","                self.children.append(child)\n","\n","        return child\n","\n","\n","    def backpropagate(self, value):\n","        self.value_sum += value\n","        self.visit_count += 1\n","\n","        value = self.game.get_opponent_value(value)\n","        if self.parent is not None:\n","            self.parent.backpropagate(value)\n","\n","class MCTS:\n","    def __init__(self, game, args, model):\n","        self.game = game\n","        self.args = args\n","        self.model = model\n","\n","    @torch.no_grad()\n","    def search(self, state):\n","        root = Node(self.game, self.args, state, visit_count=1)\n","\n","        policy, _ = self.model(\n","            torch.tensor(self.game.get_encoded_state(state), device=self.model.device).unsqueeze(0)\n","        )\n","        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n","        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n","            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n","\n","        valid_moves = self.game.get_valid_moves(state)\n","        policy *= valid_moves\n","        policy /= np.sum(policy)\n","        root.expand(policy)\n","\n","        for search in range(self.args['num_searches']):\n","            node = root\n","\n","            while node.is_fully_expanded():\n","                node = node.select()\n","\n","            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n","            value = self.game.get_opponent_value(value)\n","\n","            if not is_terminal:\n","                policy, value = self.model(\n","                    torch.tensor(self.game.get_encoded_state(node.state), device=self.model.device).unsqueeze(0)\n","                )\n","                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n","                valid_moves = self.game.get_valid_moves(node.state)\n","                policy *= valid_moves\n","                policy /= np.sum(policy)\n","\n","                value = value.item()\n","\n","                node.expand(policy)\n","\n","            node.backpropagate(value)\n","\n","\n","        action_probs = np.zeros(self.game.action_size)\n","        for child in root.children:\n","            action_probs[child.action_taken] = child.visit_count\n","        action_probs /= np.sum(action_probs)\n","        return action_probs\n","\n","class AlphaZero:\n","    def __init__(self, model, optimizer, game, args):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.game = game\n","        self.args = args\n","        self.mcts = MCTS(game, args, model)\n","\n","    def selfPlay(self):\n","        memory = []\n","        player = 1\n","        state = self.game.get_initial_state()\n","\n","        while True:\n","            neutral_state = self.game.change_perspective(state, player)\n","            action_probs = self.mcts.search(neutral_state)\n","\n","            memory.append((neutral_state, action_probs, player))\n","\n","\n","            temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n","            temperature_action_probs /= np.sum(temperature_action_probs)\n","            action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n","\n","            state = self.game.get_next_state(state, action, player)\n","\n","            value, is_terminal = self.game.get_value_and_terminated(state, action)\n","\n","            if is_terminal:\n","                returnMemory = []\n","                for hist_neutral_state, hist_action_probs, hist_player in memory:\n","                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n","                    returnMemory.append((\n","                        self.game.get_encoded_state(hist_neutral_state),\n","                        hist_action_probs,\n","                        hist_outcome\n","                    ))\n","                return returnMemory\n","\n","            player = self.game.get_opponent(player)\n","\n","\n","\n","    def train(self, memory):\n","        random.shuffle(memory)\n","        for batchIdx in range(0, len(memory), self.args['batch_size']):\n","            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n","            state, policy_targets, value_targets = zip(*sample)\n","\n","            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n","\n","            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n","            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n","            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n","\n","            out_policy, out_value = self.model(state)\n","\n","            policy_loss = F.cross_entropy(out_policy, policy_targets)\n","            value_loss = F.mse_loss(out_value, value_targets)\n","            loss = policy_loss + value_loss\n","\n","            self.optimizer.zero_grad() # change to self.optimizer\n","            loss.backward()\n","            self.optimizer.step() # change to self.optimizer\n","\n","    def learn(self):\n","        for iteration in range(self.args['num_iterations']):\n","            memory = []\n","\n","            self.model.eval()\n","            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n","                memory += self.selfPlay()\n","\n","            self.model.train()\n","            for epoch in trange(self.args['num_epochs']):\n","                self.train(memory)\n","\n","            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n","            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")\n","class Node_Orig:\n","    def __init__(self, game, args, state, parent=None, action_taken=None):\n","        self.game = game\n","        self.args = args\n","        self.state = state\n","        self.parent = parent\n","        self.action_taken = action_taken\n","\n","        self.children = []\n","        self.expandable_moves = game.get_valid_moves(state)\n","\n","        self.visit_count = 0\n","        self.value_sum = 0\n","\n","    def is_fully_expanded(self):\n","        return np.sum(self.expandable_moves) == 0 and len(self.children) > 0\n","\n","    def select(self):\n","        best_child = None\n","        best_ucb = -np.inf\n","\n","        for child in self.children:\n","            ucb = self.get_ucb(child)\n","            if ucb > best_ucb:\n","                best_child = child\n","                best_ucb = ucb\n","\n","        return best_child\n","\n","    def get_ucb(self, child):\n","        q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n","        return q_value + self.args['C'] * math.sqrt(math.log(self.visit_count) / child.visit_count)\n","\n","    def expand(self):\n","        action = np.random.choice(np.where(self.expandable_moves == 1)[0])\n","        self.expandable_moves[action] = 0\n","\n","        child_state = self.state.copy()\n","        child_state = self.game.get_next_state(child_state, action, 1)\n","        child_state = self.game.change_perspective(child_state, player=-1)\n","\n","        child = Node_Orig(self.game, self.args, child_state, self, action)\n","        self.children.append(child)\n","        return child\n","\n","    def simulate(self):\n","        value, is_terminal = self.game.get_value_and_terminated(self.state, self.action_taken)\n","        value = self.game.get_opponent_value(value)\n","\n","        if is_terminal:\n","            return value\n","\n","        rollout_state = self.state.copy()\n","        rollout_player = 1\n","        while True:\n","            valid_moves = self.game.get_valid_moves(rollout_state)\n","            action = np.random.choice(np.where(valid_moves == 1)[0])\n","            rollout_state = self.game.get_next_state(rollout_state, action, rollout_player)\n","            value, is_terminal = self.game.get_value_and_terminated(rollout_state, action)\n","            if is_terminal:\n","                if rollout_player == -1:\n","                    value = self.game.get_opponent_value(value)\n","                return value\n","\n","            rollout_player = self.game.get_opponent(rollout_player)\n","\n","    def backpropagate(self, value):\n","        self.value_sum += value\n","        self.visit_count += 1\n","\n","        value = self.game.get_opponent_value(value)\n","        if self.parent is not None:\n","            self.parent.backpropagate(value)\n","\n","class MCTS_Orig:\n","    def __init__(self, game, args):\n","        self.game = game\n","        self.args = args\n","\n","    def search(self, state):\n","        root = Node_Orig(self.game, self.args, state)\n","\n","        for search in range(self.args['num_searches']):\n","            node = root\n","\n","            while node.is_fully_expanded():\n","                node = node.select()\n","\n","            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n","            value = self.game.get_opponent_value(value)\n","\n","            if not is_terminal:\n","                node = node.expand()\n","                value = node.simulate()\n","\n","            node.backpropagate(value)\n","\n","\n","        action_probs = np.zeros(self.game.action_size)\n","        for child in root.children:\n","            action_probs[child.action_taken] = child.visit_count\n","        action_probs /= np.sum(action_probs)\n","        return action_probs\n","\n","@ray.remote(num_gpus=0.2)\n","def selfplay_competition(game, args, args_orig, model):\n","    #below can move to a separate function\n","    player = 1\n","    mcts = MCTS(game, args, model)\n","    mcts_orig = MCTS_Orig(game, args_orig)\n","    state = game.get_initial_state()\n","    while True:\n","        #print(state)\n","\n","        if player == 1:\n","            neutral_state = game.change_perspective(state, player)\n","            mcts_probs = mcts_orig.search(neutral_state)\n","            action = np.argmax(mcts_probs)\n","\n","        else:\n","            neutral_state = game.change_perspective(state, player)\n","            mcts_probs = mcts.search(neutral_state)\n","            action = np.argmax(mcts_probs)\n","\n","        state = game.get_next_state(state, action, player)\n","\n","        value, is_terminal = game.get_value_and_terminated(state, action)\n","\n","        if is_terminal:\n","            print(state)\n","            if value == 1:\n","                print(player, \"won\")\n","                return player\n","            else:\n","                print(\"draw\")\n","                return 0\n","            break\n","\n","        player = game.get_opponent(player)\n","\n","\n","def main():\n","    game = ConnectFour()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","    result = []\n","    ray_result = []\n","    num_competitions = 10\n","    args = {\n","        'C': 2,\n","        'num_searches': 100,\n","        'dirichlet_epsilon': 0.,\n","        'dirichlet_alpha': 0.3\n","    }\n","\n","    args_orig = {\n","        'C': 1.41,\n","        'num_searches': 10000\n","    }\n","\n","\n","    model = ResNet(game, 9, 128, device=device)\n","    model.load_state_dict(torch.load('model_7_ConnectFour.pt', map_location=device))\n","    model.eval()\n","    start = time.time()\n","\n","    for selfPlay_iteration in trange(num_competitions):\n","        result.append(selfplay_competition.remote(game, args, args_orig, model))\n","    output = ray.get(result)\n","\n","    for i in range(len(output)):\n","        ray_result.append(output[i])\n","\n","    print(ray_result)\n","\n","    runtime = time.time()-start\n","    print(runtime, \" second\")\n","\n","\n","def test():\n","\n","    tictactoe = TicTacToe()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    state = tictactoe.get_initial_state()\n","    state = tictactoe.get_next_state(state, 2, -1)\n","    state = tictactoe.get_next_state(state, 4, -1)\n","    state = tictactoe.get_next_state(state, 6, 1)\n","    state = tictactoe.get_next_state(state, 8, 1)\n","\n","    print(state)\n","\n","    encoded_state = tictactoe.get_encoded_state(state)\n","\n","    print(encoded_state)\n","\n","    tensor_state = torch.tensor(encoded_state, device=device).unsqueeze(0)\n","\n","    model = ResNet(tictactoe, 4, 64, device=device)\n","    model.load_state_dict(torch.load('model_2.pt', map_location=device))\n","\n","    model.eval()\n","\n","    policy, value = model(tensor_state)\n","    value = value.item()\n","    policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n","\n","    print(value, policy)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"89oGVCf8mZHk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["    ### Start Training\n","    game = ConnectFour()\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model = ResNet(game, 9, 128, device)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n","\n","    args = {\n","        'C': 2,\n","        'num_searches': 600,\n","        'num_iterations': 8,\n","        'num_selfPlay_iterations': 500,\n","        'num_epochs': 4,\n","        'batch_size': 128,\n","        'temperature': 1.25,\n","        'dirichlet_epsilon': 0.25,\n","        'dirichlet_alpha': 0.3\n","    }\n","\n","    alphaZero = AlphaZero(model, optimizer, game, args)\n","    alphaZero.learn()"],"metadata":{"id":"lhtEPwmv-B7j","colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["d86bf1fd196544b6a1c01875d173beb9","e1186a282fa0447e85ef10c97183be4a","106133254d234474a892386f53ddd2de","6515037cec0344ed9fdea0b5c8b5cfab","927dad273e384632b8f083a19fc965df","ca2570661a934fb08d3e1aeefc9f393d","34cbf38dd87945ef952e3c8cfe9e3a8e","5e6882d072884320944d11ce4f06a5a1","26e9773c57014215ae9cc7f7c698f4c1","f6eedbbfa72046e3a79ce94049f83a81","2ce0b3e671914a6cb392584909ec046c"]},"executionInfo":{"status":"error","timestamp":1713259815714,"user_tz":-480,"elapsed":16147,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"ed603659-7012-410e-8336-714473ef4014"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/500 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d86bf1fd196544b6a1c01875d173beb9"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-3f18367a0c88>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0malphaZero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlphaZero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0malphaZero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-a8363ad3aac1>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mselfPlay_iteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_selfPlay_iterations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mmemory\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselfPlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-a8363ad3aac1>\u001b[0m in \u001b[0;36mselfPlay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mneutral_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_perspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneutral_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneutral_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-a8363ad3aac1>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_terminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 policy, value = self.model(\n\u001b[0m\u001b[1;32m    232\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoded_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-a8363ad3aac1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mresBlock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackBone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicyHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalueHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-a8363ad3aac1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["    ### test the trained model, not used in Connect4\n","    ### test()"],"metadata":{"id":"KDxMFtBi-MGC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710837309874,"user_tz":-480,"elapsed":483,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"172efc82-eba5-4868-99d7-ca47b2acb6b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.  0. -1.]\n"," [ 0. -1.  0.]\n"," [ 1.  0.  1.]]\n","[[[0. 0. 1.]\n","  [0. 1. 0.]\n","  [0. 0. 0.]]\n","\n"," [[1. 1. 0.]\n","  [1. 0. 1.]\n","  [0. 1. 0.]]\n","\n"," [[0. 0. 0.]\n","  [0. 0. 0.]\n","  [1. 0. 1.]]]\n","-0.08826334774494171 [0.07518821 0.08451733 0.11294591 0.09931102 0.0952905  0.17337684\n"," 0.12486862 0.14422536 0.09027616]\n"]}]},{"cell_type":"code","source":["  ### play the actual game\n","  main()"],"metadata":{"id":"pqW64Q3t-PCS","colab":{"base_uri":"https://localhost:8080/","height":746,"referenced_widgets":["444a19ac87fb4f739b7e194350df13a6","1cc4e3656e9b439e9676b872bbdd165e","08fd3e8e3d7647348f147864896917ef","ff2e32d9178f49cc80b233fbc2da216c","445b37d1751d4de28c38d795b201c59f","0a088d99dda34e6184d5ffcbe0186428","44dec3690ada4b8fb683c5c8555423e0","7b53cfa79dc84869babc9d8edbb34a0b","74ddd52026294163ad3b4d042f1a3b78","71027508e79442bb858652662838a920","87f0386fbab54007af13b614d8dd5e8e"]},"executionInfo":{"status":"ok","timestamp":1713351507024,"user_tz":-480,"elapsed":1125195,"user":{"displayName":"David Mak","userId":"16330670194757710136"}},"outputId":"86a1e87f-d914-49d9-e99f-da9f9c234987"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"444a19ac87fb4f739b7e194350df13a6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[36m(selfplay_competition pid=3748)\u001b[0m [[ 1.  0.  1. -1.  1.  0.  0.]\n","\u001b[36m(selfplay_competition pid=3748)\u001b[0m  [-1.  0. -1. -1. -1.  0.  0.]\n","\u001b[36m(selfplay_competition pid=3748)\u001b[0m  [ 1.  0. -1.  1. -1.  0. -1.]\n","\u001b[36m(selfplay_competition pid=3748)\u001b[0m  [-1.  1. -1. -1.  1.  0.  1.]\n","\u001b[36m(selfplay_competition pid=3748)\u001b[0m  [ 1. -1.  1. -1.  1.  0.  1.]\n","\u001b[36m(selfplay_competition pid=3748)\u001b[0m  [ 1. -1.  1.  1. -1.  0.  1.]]\n","\u001b[36m(selfplay_competition pid=3748)\u001b[0m 1 won\n","\u001b[36m(selfplay_competition pid=3742)\u001b[0m [[ 0.  1.  0. -1.  1.  0. -1.]\n","\u001b[36m(selfplay_competition pid=3742)\u001b[0m  [-1.  1. -1. -1.  1. -1.  1.]\n","\u001b[36m(selfplay_competition pid=3742)\u001b[0m  [ 1. -1.  1.  1.  1. -1.  1.]]\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(selfplay_competition pid=3742)\u001b[0m 1 won\n","\u001b[36m(selfplay_competition pid=4714)\u001b[0m [[-1.  0. -1. -1.  0. -1. -1.]\n","\u001b[36m(selfplay_competition pid=4714)\u001b[0m  [-1.  0.  1. -1. -1. -1. -1.]\n","\u001b[36m(selfplay_competition pid=4714)\u001b[0m  [-1.  1.  1.  1. -1. -1.  1.]]\n","\u001b[36m(selfplay_competition pid=4714)\u001b[0m -1 won\n","\u001b[36m(selfplay_competition pid=4714)\u001b[0m  [ 1.  1.  1. -1.  1.  1.  1.]\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(selfplay_competition pid=4830)\u001b[0m [[ 0.  0.  0.  0.  0.  0.  0.]\n","\u001b[36m(selfplay_competition pid=5732)\u001b[0m  [-1. -1.  1.  1. -1.  0.  1.]]\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(selfplay_competition pid=5732)\u001b[0m -1 won\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(selfplay_competition pid=5732)\u001b[0m  [ 0. -1. -1. -1.  1.  0.  1.]\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(selfplay_competition pid=5732)\u001b[0m [[ 0.  0.  0.  1.  0.  0.  0.]\n","\u001b[36m(selfplay_competition pid=5687)\u001b[0m [[ 0.  0.  1. -1. -1. -1. -1.]\n","\u001b[36m(selfplay_competition pid=5687)\u001b[0m -1 won\n","\u001b[36m(selfplay_competition pid=5687)\u001b[0m  [ 1. -1.  1.  1. -1.  1.  1.]]\u001b[32m [repeated 5x across cluster]\u001b[0m\n","\u001b[36m(selfplay_competition pid=6681)\u001b[0m [[-1.  0.  1. -1. -1.  1. -1.]\n","\u001b[36m(selfplay_competition pid=6681)\u001b[0m  [-1.  0. -1. -1. -1.  1.  1.]\n","\u001b[36m(selfplay_competition pid=6681)\u001b[0m  [-1. -1.  1. -1. -1.  1.  1.]\n","\u001b[36m(selfplay_competition pid=6681)\u001b[0m 1 won\n","\u001b[36m(selfplay_competition pid=6681)\u001b[0m  [ 1. -1. -1.  1.  1. -1.  1.]]\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(selfplay_competition pid=6614)\u001b[0m [[ 1.  0.  1.  1. -1.  1. -1.]\n","\u001b[36m(selfplay_competition pid=6614)\u001b[0m  [-1.  0. -1. -1. -1.  1.  1.]\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(selfplay_competition pid=6614)\u001b[0m 1 won\n","\u001b[36m(selfplay_competition pid=6614)\u001b[0m  [ 1. -1.  1.  1. -1. -1. -1.]]\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(selfplay_competition pid=7754)\u001b[0m -1 won\n","\u001b[36m(selfplay_competition pid=7754)\u001b[0m [[ 0.  1.  1. -1.  0.  0. -1.]\n","\u001b[36m(selfplay_competition pid=7754)\u001b[0m  [-1.  1.  1.  1. -1. -1.  1.]]\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(selfplay_competition pid=7754)\u001b[0m  [ 1.  1.  1. -1.  1.  1. -1.]\u001b[32m [repeated 3x across cluster]\u001b[0m\n","[1, 1, -1, -1, -1, -1, 1, 1, 0, -1]\n","1124.3643209934235  second\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"EgzSaetK-XSy"},"execution_count":null,"outputs":[]}]}